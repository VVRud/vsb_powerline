{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>What I have</h1>\n",
    "\n",
    "**From signal**\n",
    "(everywhere can be used std_normalization):\n",
    "\n",
    "- Original signal\n",
    "- Denoised signal\n",
    "- Noise (difference between signals)\n",
    "- Mean of noiseless signal\n",
    "- Mean of original signal\n",
    "\n",
    "**From other data**:\n",
    "\n",
    "- Metrics of signal\n",
    "- Frequency domain of original signal\n",
    "- Spectrogram of signal, where channels are (denoised, original)\n",
    "\n",
    "<h1>What I should use</h1>\n",
    "\n",
    "- Denoised signal, using wavelet transform (800_000)\n",
    "    - **\\[Res(ODE)-Conv\\]+Pool x 2-4** -> **B-LSTM x 2-4** -> **Dense**<br>Put dropout and batch normalization in between.\n",
    "- Mean of noiseless signal (800_000)\n",
    "    - **\\[Res(ODE)-Conv\\]+Pool x 2-4** -> **B-LSTM x 2-4** -> **Dense**<br>Put dropout and batch normalization in between.\n",
    "- Metrics of signal (19)\n",
    "    - **Dense x 2-4**\n",
    "    - **Gradient boosting**\n",
    "- Spectrogram (129 x 3_571 x 2)\n",
    "    - **\\[Res(ODE)-Conv2D\\]+Pool x 4-8** -> **Dense**<br>Put dropout and batch normalization in between.\n",
    "- Frequency domain of a signal (1000)\n",
    "    - **\\[Res(ODE)-Conv\\]+Pool x 2-4** -> **B-LSTM x 2-4** -> **Dense**<br>Put dropout and batch normalization in between.\n",
    "    \n",
    "<h1>Final Model</h1>\n",
    "\n",
    "Input: stacked into vector (predicted probabilities of all models, \\[output of the last layer\\] x 5)\n",
    "- **Dense x 2-4**\n",
    "- **Gradient boosting**\n",
    "Output: final prediction\n",
    "\n",
    "Optimize threshhold for matthews correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T19:50:43.695705Z",
     "start_time": "2019-01-24T19:50:40.024697Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pywt as pw\n",
    "from scipy import fftpack, signal, stats\n",
    "import patsy\n",
    "from statsmodels.robust import mad\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "from plotting import plot_phases, plot_single_func, plot_phases_func, plot_values, plot_values_loglog\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "import multiprocessing as mp\n",
    "import gc\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T19:50:46.573251Z",
     "start_time": "2019-01-24T19:50:46.565682Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "NUM_OF_MEASURES = 100\n",
    "COLS_STR = [str(i) for i in range(3 * NUM_OF_MEASURES)]\n",
    "COLS_INT = [i for i in range(3 * NUM_OF_MEASURES)]\n",
    "\n",
    "TR_PQ = '../data/parquet/train.parquet'\n",
    "TR_META = '../data/meta/metadata_train.csv'\n",
    "\n",
    "TS_PQ = '../data/parquet/test.parquet'\n",
    "TS_META = '../data/meta/metadata_test.csv'\n",
    "\n",
    "TR_H5 = '../data/hdf5/train.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T19:50:47.428022Z",
     "start_time": "2019-01-24T19:50:47.371040Z"
    }
   },
   "outputs": [],
   "source": [
    "train_meta = pd.read_csv(TR_META)\n",
    "test_meta = pd.read_csv(TS_META)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T19:51:05.433062Z",
     "start_time": "2019-01-24T19:51:05.428318Z"
    }
   },
   "outputs": [],
   "source": [
    "WAVELET_TYPE = 'db6'\n",
    "WAVELET_LEVEL = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T19:51:06.933352Z",
     "start_time": "2019-01-24T19:51:06.919851Z"
    },
    "code_folding": [
     0,
     16,
     19
    ]
   },
   "outputs": [],
   "source": [
    "def denoise_phase(phase):\n",
    "    wavelet = pw.Wavelet(WAVELET_TYPE)\n",
    "    wc = pw.wavedec(phase, wavelet, level=WAVELET_LEVEL)\n",
    "    sigma = mad(wc[-1])\n",
    "    threshold = sigma * np.sqrt(2 * np.log(len(phase)))\n",
    "\n",
    "    wc_r = wc[:]\n",
    "    wc_r[1:] = (pw.threshold(x, threshold) for x in wc[1:])\n",
    "    return pw.waverec(wc_r, wavelet)\n",
    "\n",
    "def std_normalize_phase(phase):\n",
    "    return (phase - np.mean(phase)) / np.std(phase)\n",
    "\n",
    "def denoise_normalize_phase(phase):\n",
    "    return std_normalize_phase(denoise_phase(phase))\n",
    "\n",
    "def minmax_normalize(phase):\n",
    "    return (phase - np.min(phase)) / (np.max(phase) - np.min(phase))\n",
    "\n",
    "def mean(phases):\n",
    "    return np.mean(phases, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T19:51:07.424022Z",
     "start_time": "2019-01-24T19:51:07.410818Z"
    },
    "code_folding": [
     0,
     7,
     11,
     14,
     17,
     23
    ]
   },
   "outputs": [],
   "source": [
    "def get_phases(df, measurement_id):\n",
    "    p1 = df[str(measurement_id * 3)].values\n",
    "    p2 = df[str(measurement_id * 3 + 1)].values\n",
    "    p3 = df[str(measurement_id * 3 + 2)].values\n",
    "\n",
    "    return p1, p2, p3\n",
    "\n",
    "def triple_denoise(df, measurement_id):\n",
    "    return np.asarray(\n",
    "        [denoise_phase(phase) for phase in get_phases(df, measurement_id)])\n",
    "\n",
    "def original_mean(df, measurement_id):\n",
    "    return mean(get_phases(df, measurement_id))\n",
    "\n",
    "def denoised_mean(df, measurement_id):\n",
    "    return mean(triple_denoise(df, measurement_id))\n",
    "\n",
    "def denoise_normalize(df, measurement_id):\n",
    "    return np.asarray([\n",
    "        std_normalize_phase(phase)\n",
    "        for phase in triple_denoise(df, measurement_id)\n",
    "    ])\n",
    "\n",
    "def original_normalize(df, measurement_id):\n",
    "    return np.asarray([\n",
    "        std_normalize_phase(phase) for phase in get_phases(df, measurement_id)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T19:51:08.027150Z",
     "start_time": "2019-01-24T19:51:08.012547Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def metrics(phase, asdict=False):\n",
    "    f, Pxx = signal.welch(phase)\n",
    "    ix_mx = np.argmax(Pxx)\n",
    "    ix_mn = np.argmin(Pxx)\n",
    "\n",
    "    d = {\n",
    "        'mean_signal': np.mean(phase),\n",
    "        'std_signal': np.std(phase),\n",
    "        'kurtosis_signal': stats.kurtosis(phase),\n",
    "        'skewness_signal': stats.skew(phase),\n",
    "        \n",
    "        'mean_amp': np.mean(Pxx),\n",
    "        'std_amp': np.std(Pxx),\n",
    "        'median_amp': np.median(Pxx),\n",
    "        'kurtosis_amp': stats.kurtosis(Pxx),\n",
    "        'skewness_amp': stats.skew(Pxx),\n",
    "\n",
    "        'max_signal': np.max(phase),\n",
    "        'min_signal': np.min(phase),\n",
    "        \n",
    "        'max_amp': Pxx[ix_mx],\n",
    "        'min_amp': Pxx[ix_mn],\n",
    "        \n",
    "        'max_freq': f[ix_mx],\n",
    "        'min_freq': f[ix_mn],\n",
    "        \n",
    "        'strong_amp': np.sum(Pxx > 2.5),\n",
    "        'weak_amp': np.sum(Pxx < 0.4),\n",
    "    }\n",
    "\n",
    "    if asdict:\n",
    "        return d\n",
    "    else:\n",
    "        return np.asarray(list(d.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T19:51:08.529258Z",
     "start_time": "2019-01-24T19:51:08.523825Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def onehot_phase(phase):\n",
    "    return [0 if phase == 0 else 1, 0 if phase == 1 else 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T19:51:10.223165Z",
     "start_time": "2019-01-24T19:51:10.212812Z"
    },
    "code_folding": [
     0,
     11
    ]
   },
   "outputs": [],
   "source": [
    "def get_freq(val, n, d):\n",
    "    sig_fft = fftpack.fft(val, n=n)\n",
    "    sample_freq = fftpack.fftfreq(n=n, d=d)\n",
    "    pos_mask = np.where(sample_freq >= 0)\n",
    "\n",
    "    freqs = sample_freq[pos_mask][1:]\n",
    "    power = np.abs(sig_fft)[pos_mask][1:]\n",
    "\n",
    "    return freqs, power\n",
    "\n",
    "def get_freq_dom(values, denoised=None, n=1000, d=(0.02 / 800000.)):\n",
    "    size = n * 2 + 2\n",
    "    \n",
    "    if denoised is None:\n",
    "        denoised = denoise_phase(values)\n",
    "    \n",
    "    _, p1 = get_freq(values, size, d)\n",
    "    _, p2 = get_freq(denoised, size, d)\n",
    "    \n",
    "    return np.reshape(np.asarray([p1, p2]).T, (n, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T19:51:12.806787Z",
     "start_time": "2019-01-24T19:51:12.796667Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_spectrogram(values, denoised=None, fs=1 / (2e-2 / 800000), uselog=True):\n",
    "    if denoised is None:\n",
    "        denoised = denoise_phase(values)\n",
    "\n",
    "    _, _, Sx1 = signal.spectrogram(denoised, fs)\n",
    "    _, _, Sx2 = signal.spectrogram(values, fs)\n",
    "\n",
    "    ret = np.concatenate((\n",
    "        np.reshape(Sx1, (Sx1.shape[0], Sx1.shape[1], -1)),\n",
    "        np.reshape(Sx2, (Sx2.shape[0], Sx2.shape[1], -1)),\n",
    "    ),\n",
    "                         axis=-1)\n",
    "\n",
    "    if uselog:\n",
    "        return np.log10(ret)\n",
    "    else:\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paperspace parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T19:51:14.643406Z",
     "start_time": "2019-01-24T19:51:14.630785Z"
    },
    "code_folding": [
     0,
     24
    ]
   },
   "outputs": [],
   "source": [
    "def parallel_apply_along_axis(func1d, axis, arr, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Like numpy.apply_along_axis(), but takes advantage of multiple\n",
    "    cores.\n",
    "    \"\"\"        \n",
    "    # Effective axis where apply_along_axis() will be applied by each\n",
    "    # worker (any non-zero axis number would work, so as to allow the use\n",
    "    # of `np.array_split()`, which is only done on axis 0):\n",
    "    effective_axis = 1 if axis == 0 else axis\n",
    "    if effective_axis != axis:\n",
    "        arr = arr.swapaxes(axis, effective_axis)\n",
    "\n",
    "    # Chunks for the mapping (only a few chunks):\n",
    "    chunks = [(func1d, effective_axis, sub_arr, args, kwargs)\n",
    "              for sub_arr in np.array_split(arr, mp.cpu_count())]\n",
    "\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    individual_results = pool.map(unpacking_apply_along_axis, chunks)\n",
    "    # Freeing the workers:\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    return np.concatenate(individual_results)\n",
    "\n",
    "def unpacking_apply_along_axis(tp):\n",
    "    func1d, axis, arr, args, kwargs = tp\n",
    "    \"\"\"\n",
    "    Like numpy.apply_along_axis(), but and with arguments in a tuple\n",
    "    instead.\n",
    "\n",
    "    This function is useful with multiprocessing.Pool().map(): (1)\n",
    "    map() only handles functions that take a single argument, and (2)\n",
    "    this function can generally be imported from a module, as required\n",
    "    by map().\n",
    "    \"\"\"\n",
    "    return np.apply_along_axis(func1d, axis, arr, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T19:51:14.842023Z",
     "start_time": "2019-01-24T19:51:14.818693Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def parallel_proc_h5(name, data, meta, batch=1000):\n",
    "    steps = int(np.ceil(data.shape[0] / batch))\n",
    "\n",
    "    dir_file = '../data/hdf5/' + name + '.hdf5'\n",
    "    print('Creating hdf5 file in directory: {}'.format(dir_file))\n",
    "    hd_file = h5py.File(dir_file, mode='a')\n",
    "\n",
    "    print('Creating datasets: ', end='')\n",
    "    denoised_ds = hd_file.create_dataset(\n",
    "        'denoised',\n",
    "        shape=data.shape,\n",
    "        dtype=np.float32,\n",
    "        chunks=True,\n",
    "        compression=\"gzip\",\n",
    "        compression_opts=6)\n",
    "    print('denoised, ', end='')\n",
    "    \n",
    "    metrics_ds = hd_file.create_dataset(\n",
    "        'metrics', shape=(data.shape[0], 19), dtype=np.float32, chunks=True)\n",
    "    print('metrics, ', end='')\n",
    "    \n",
    "    spectrogram_ds = hd_file.create_dataset(\n",
    "        'spectrogram',\n",
    "        shape=(data.shape[0], 129, 3571, 2),\n",
    "        dtype=np.float32,\n",
    "        chunks=True,\n",
    "        compression=\"gzip\",\n",
    "        compression_opts=6)\n",
    "    print('spectrogram, ', end='')\n",
    "    \n",
    "    freq_dom_ds = hd_file.create_dataset(\n",
    "        'freq_dom',\n",
    "        shape=(data.shape[0], 1000, 2),\n",
    "        dtype=np.float32,\n",
    "        chunks=True)\n",
    "    print('freq_dom.')\n",
    "\n",
    "    t = tnrange(steps)\n",
    "    for i in t:\n",
    "        start = i * batch\n",
    "        finish = (i + 1) * batch if i + 1 != steps else data.shape[0]\n",
    "\n",
    "        t.set_description('Denoising')\n",
    "        denoised_ds[start:finish] = parallel_apply_along_axis(\n",
    "            denoise_normalize_phase, 1, data[start:finish])\n",
    "\n",
    "        t.set_description('Metrics')\n",
    "        ds = parallel_apply_along_axis(metrics, 1, data[start:finish])\n",
    "        oh = parallel_apply_along_axis(\n",
    "            onehot_phase, 1, meta['phase'].values[start:finish].reshape(\n",
    "                finish - start, 1))\n",
    "        metrics_ds[start:finish] = np.concatenate([ds, oh], axis=1)\n",
    "\n",
    "        t.set_description('Spectrogram')\n",
    "        spectrogram_ds[start:finish] = parallel_apply_along_axis(\n",
    "            get_spectrogram, 1, data[start:finish])\n",
    "\n",
    "        t.set_description('Frequency')\n",
    "        freq_dom_ds[start:finish] = parallel_apply_along_axis(\n",
    "            get_freq_dom, 1, data[start:finish])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# May help but not now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:34:00.658017Z",
     "start_time": "2019-01-15T16:34:00.649822Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cross_corr(df, measurement_id, mode='same'):  #same, full\n",
    "    p1, p2, p3 = triple_denoise(df, measurement_id)\n",
    "\n",
    "    c12 = signal.correlate(p1, p2, mode=mode)\n",
    "    c13 = signal.correlate(p1, p3, mode=mode)\n",
    "    c23 = signal.correlate(p2, p3, mode=mode)\n",
    "\n",
    "    return np.asarray([c12, c13, c23])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T19:40:09.275319Z",
     "start_time": "2019-01-15T19:39:47.643812Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_phases(train, train_meta, 0, url=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T20:14:46.239055Z",
     "start_time": "2019-01-15T20:14:25.352719Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_phases_func(\n",
    "    train, train_meta, 0, func=triple_denoise, name='denoise', url=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T19:44:19.981141Z",
     "start_time": "2019-01-15T19:44:19.916610Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "denoise_phase(train['0'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T19:41:23.597920Z",
     "start_time": "2019-01-15T19:41:16.597115Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_single_func(\n",
    "    train, train_meta, 0, func=original_mean, name='orig_mean', url=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T19:42:09.554583Z",
     "start_time": "2019-01-15T19:42:01.753814Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_single_func(\n",
    "    train, train_meta, 0, func=denoised_mean, name='wavelet_mean', url=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T19:53:43.790512Z",
     "start_time": "2019-01-24T19:53:43.784281Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import (Bidirectional, LSTM, Dense, TimeDistributed, Conv1D,\n",
    "                          Input, Add, BatchNormalization, ReLU, Dropout, Flatten, Activation)\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T19:51:26.397430Z",
     "start_time": "2019-01-24T19:51:26.377917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['denoised', 'freq_dom', 'metrics', 'spectrogram']>\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File(TR_H5, mode='r+')\n",
    "print(f.keys())\n",
    "denoised = f['denoised']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T19:51:29.265729Z",
     "start_time": "2019-01-24T19:51:29.254600Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "\n",
    "def matthews_correlation(y_true, y_pred):\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "\n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    "\n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    "\n",
    "    numerator = (tp * tn - fp * fn)\n",
    "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "\n",
    "    return numerator / (denominator + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T19:59:18.419835Z",
     "start_time": "2019-01-24T19:59:18.406678Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def res_layer(input_data, filters, kernel_size, block_num=None):\n",
    "    if block_num is None:\n",
    "        raise ValueError('Block number is not defined')\n",
    "\n",
    "    block = 'res_block' + str(block_num) + '_'\n",
    "    inp_ = input_data\n",
    "\n",
    "    out = Conv1D(\n",
    "        filters, kernel_size, padding='same', name=block + 'conv1')(input_data)\n",
    "    out = BatchNormalization(name=block + 'bn1')(out)\n",
    "    out = ReLU(name=block + 'relu1')(out)\n",
    "\n",
    "    #     out = Dropout(drop, name=block + 'drop')(out)\n",
    "\n",
    "    out = Conv1D(\n",
    "        filters, kernel_size, padding='same', name=block + 'conv2')(out)\n",
    "    out = BatchNormalization(name=block + 'bn2')(out)\n",
    "\n",
    "    out = Add(name=block + 'add')([out, inp_])\n",
    "    out = ReLU(name=block + 'relu2')(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T20:22:34.529908Z",
     "start_time": "2019-01-24T20:22:34.509638Z"
    }
   },
   "outputs": [],
   "source": [
    "filters = [4, 8, 16]\n",
    "kernel = [32, 32, 32]\n",
    "\n",
    "\n",
    "def get_model(block, kernel, warm=False):\n",
    "    input_model = Input(shape=(800000, 1), name='Input')\n",
    "\n",
    "    out = Conv1D(4, 128, strides=16, name='in_conv')(input_model)\n",
    "    out = BatchNormalization(name='in_bn')(out)\n",
    "    out = ReLU(name='in_relu')(out)\n",
    "\n",
    "#     out = res_layer(out, block[0], kernel[0], block_num=1)\n",
    "    \n",
    "    out = Conv1D(block[0], 64, strides=4, name='1_conv')(out)\n",
    "    out = BatchNormalization(name='1_bn')(out)\n",
    "    out = ReLU(name='1_relu')(out)\n",
    "\n",
    "    out = res_layer(out, block[0], kernel[0], block_num=1)\n",
    "\n",
    "    out = Conv1D(block[1], 64, strides=4, name='2_conv')(out)\n",
    "    out = BatchNormalization(name='2_bn')(out)\n",
    "    out = ReLU(name='2_relu')(out)\n",
    "\n",
    "    out = res_layer(out, block[1], kernel[1], block_num=2)\n",
    "\n",
    "    out = Conv1D(block[2], 64, strides=4, name='3_conv')(out)\n",
    "    out = BatchNormalization(name='3_bn')(out)\n",
    "    out = ReLU(name='3_relu')(out)\n",
    "\n",
    "    out = res_layer(out, block[2], kernel[2], block_num=3)\n",
    "\n",
    "    out = Conv1D(32, 32, strides=4, name='4_conv')(out)\n",
    "    out = BatchNormalization(name='4_bn')(out)\n",
    "    out = ReLU()(out)\n",
    "\n",
    "#     b_lstm1 = Bidirectional(LSTM(32, return_sequences=True), merge_mode='sum', name='bidirectional1')(bnorm4)\n",
    "    out = Bidirectional(LSTM(128, return_sequences=False), merge_mode='sum', name='bidirectional2')(out)\n",
    "\n",
    "#     flat = Flatten()(out)\n",
    "\n",
    "    out = Dense(1, name='dense_out')(out)\n",
    "    output_model = Activation('sigmoid')(out)\n",
    "\n",
    "    model = Model(inputs=input_model, outputs=output_model)\n",
    "    if warm: model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T19:54:12.219211Z",
     "start_time": "2019-01-24T19:54:12.207631Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "under_sample = RandomUnderSampler()\n",
    "indicies = under_sample.fit_resample(\n",
    "    train_meta['signal_id'].values.reshape((-1, 1)),\n",
    "    train_meta['target'].values.reshape((-1, 1)))\n",
    "data = np.concatenate(indicies, axis=1)\n",
    "data = data[data[:,0].argsort()]\n",
    "\n",
    "indicies, y_train = data[: ,0].tolist(), data[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T19:58:50.887960Z",
     "start_time": "2019-01-24T19:54:20.003092Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(denoised[indicies], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T19:59:08.705200Z",
     "start_time": "2019-01-24T19:59:08.700310Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = X_train.reshape((-1, X_train.shape[1], 1)), y_train.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T20:22:51.821768Z",
     "start_time": "2019-01-24T20:22:48.337242Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 800000, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "in_conv (Conv1D)                (None, 49993, 4)     516         Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "in_bn (BatchNormalization)      (None, 49993, 4)     16          in_conv[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "in_relu (ReLU)                  (None, 49993, 4)     0           in_bn[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "1_conv (Conv1D)                 (None, 12483, 4)     1028        in_relu[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "1_bn (BatchNormalization)       (None, 12483, 4)     16          1_conv[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "1_relu (ReLU)                   (None, 12483, 4)     0           1_bn[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "res_block1_conv1 (Conv1D)       (None, 12483, 4)     516         1_relu[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res_block1_bn1 (BatchNormalizat (None, 12483, 4)     16          res_block1_conv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res_block1_relu1 (ReLU)         (None, 12483, 4)     0           res_block1_bn1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res_block1_conv2 (Conv1D)       (None, 12483, 4)     516         res_block1_relu1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res_block1_bn2 (BatchNormalizat (None, 12483, 4)     16          res_block1_conv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res_block1_add (Add)            (None, 12483, 4)     0           res_block1_bn2[0][0]             \n",
      "                                                                 1_relu[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res_block1_relu2 (ReLU)         (None, 12483, 4)     0           res_block1_add[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "2_conv (Conv1D)                 (None, 3105, 8)      2056        res_block1_relu2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "2_bn (BatchNormalization)       (None, 3105, 8)      32          2_conv[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "2_relu (ReLU)                   (None, 3105, 8)      0           2_bn[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "res_block2_conv1 (Conv1D)       (None, 3105, 8)      2056        2_relu[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res_block2_bn1 (BatchNormalizat (None, 3105, 8)      32          res_block2_conv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res_block2_relu1 (ReLU)         (None, 3105, 8)      0           res_block2_bn1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res_block2_conv2 (Conv1D)       (None, 3105, 8)      2056        res_block2_relu1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res_block2_bn2 (BatchNormalizat (None, 3105, 8)      32          res_block2_conv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res_block2_add (Add)            (None, 3105, 8)      0           res_block2_bn2[0][0]             \n",
      "                                                                 2_relu[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res_block2_relu2 (ReLU)         (None, 3105, 8)      0           res_block2_add[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "3_conv (Conv1D)                 (None, 761, 16)      8208        res_block2_relu2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "3_bn (BatchNormalization)       (None, 761, 16)      64          3_conv[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "3_relu (ReLU)                   (None, 761, 16)      0           3_bn[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "res_block3_conv1 (Conv1D)       (None, 761, 16)      8208        3_relu[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res_block3_bn1 (BatchNormalizat (None, 761, 16)      64          res_block3_conv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res_block3_relu1 (ReLU)         (None, 761, 16)      0           res_block3_bn1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res_block3_conv2 (Conv1D)       (None, 761, 16)      8208        res_block3_relu1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res_block3_bn2 (BatchNormalizat (None, 761, 16)      64          res_block3_conv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res_block3_add (Add)            (None, 761, 16)      0           res_block3_bn2[0][0]             \n",
      "                                                                 3_relu[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res_block3_relu2 (ReLU)         (None, 761, 16)      0           res_block3_add[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "4_conv (Conv1D)                 (None, 183, 32)      16416       res_block3_relu2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "4_bn (BatchNormalization)       (None, 183, 32)      128         4_conv[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 183, 32)      0           4_bn[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional2 (Bidirectional)  (None, 128)          164864      re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_out (Dense)               (None, 1)            129         bidirectional2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 1)            0           dense_out[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 215,257\n",
      "Trainable params: 215,017\n",
      "Non-trainable params: 240\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(filters, kernel, True)\n",
    "m_tb = TensorBoard(log_dir='../logs/model_next', histogram_freq=0, write_graph=True)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', matthews_correlation]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T20:34:58.446366Z",
     "start_time": "2019-01-24T20:23:04.825214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1050/1050 [==============================] - 24s 22ms/step - loss: 0.6966 - acc: 0.5152 - matthews_correlation: 0.0642\n",
      "Epoch 2/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.6794 - acc: 0.5600 - matthews_correlation: 0.1269\n",
      "Epoch 3/50\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.6637 - acc: 0.5752 - matthews_correlation: 0.1494\n",
      "Epoch 4/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.6561 - acc: 0.5733 - matthews_correlation: 0.1533\n",
      "Epoch 5/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.6531 - acc: 0.5886 - matthews_correlation: 0.1840\n",
      "Epoch 6/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.6336 - acc: 0.6057 - matthews_correlation: 0.2196\n",
      "Epoch 7/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.5934 - acc: 0.6848 - matthews_correlation: 0.3918\n",
      "Epoch 8/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.5887 - acc: 0.7029 - matthews_correlation: 0.4112\n",
      "Epoch 9/50\n",
      "1050/1050 [==============================] - 13s 13ms/step - loss: 0.5513 - acc: 0.6895 - matthews_correlation: 0.3867\n",
      "Epoch 10/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.5258 - acc: 0.7343 - matthews_correlation: 0.4925\n",
      "Epoch 11/50\n",
      "1050/1050 [==============================] - 13s 13ms/step - loss: 0.5163 - acc: 0.7448 - matthews_correlation: 0.5068\n",
      "Epoch 12/50\n",
      "1050/1050 [==============================] - 13s 12ms/step - loss: 0.5282 - acc: 0.7114 - matthews_correlation: 0.4478\n",
      "Epoch 13/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.5041 - acc: 0.7448 - matthews_correlation: 0.5176\n",
      "Epoch 14/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.5106 - acc: 0.7543 - matthews_correlation: 0.5149\n",
      "Epoch 15/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.4624 - acc: 0.7819 - matthews_correlation: 0.5772\n",
      "Epoch 16/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.4760 - acc: 0.7752 - matthews_correlation: 0.5745\n",
      "Epoch 17/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.6514 - acc: 0.6362 - matthews_correlation: 0.2727\n",
      "Epoch 18/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.5602 - acc: 0.7010 - matthews_correlation: 0.4316\n",
      "Epoch 19/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.5418 - acc: 0.7438 - matthews_correlation: 0.4969\n",
      "Epoch 20/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.4731 - acc: 0.7790 - matthews_correlation: 0.5916\n",
      "Epoch 21/50\n",
      "1050/1050 [==============================] - 13s 13ms/step - loss: 0.4485 - acc: 0.7857 - matthews_correlation: 0.5854\n",
      "Epoch 22/50\n",
      "1050/1050 [==============================] - 13s 13ms/step - loss: 0.4113 - acc: 0.8238 - matthews_correlation: 0.6492\n",
      "Epoch 23/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.4145 - acc: 0.8495 - matthews_correlation: 0.7046\n",
      "Epoch 24/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.3796 - acc: 0.8448 - matthews_correlation: 0.6945\n",
      "Epoch 25/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.3678 - acc: 0.8524 - matthews_correlation: 0.7075\n",
      "Epoch 26/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.3658 - acc: 0.8524 - matthews_correlation: 0.7092\n",
      "Epoch 27/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.3719 - acc: 0.8533 - matthews_correlation: 0.7123\n",
      "Epoch 28/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.3386 - acc: 0.8619 - matthews_correlation: 0.7266\n",
      "Epoch 29/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.3795 - acc: 0.8562 - matthews_correlation: 0.7153\n",
      "Epoch 30/50\n",
      "1050/1050 [==============================] - 13s 13ms/step - loss: 0.3426 - acc: 0.8629 - matthews_correlation: 0.7329\n",
      "Epoch 31/50\n",
      "1050/1050 [==============================] - 13s 13ms/step - loss: 0.3279 - acc: 0.8676 - matthews_correlation: 0.7352\n",
      "Epoch 32/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.3678 - acc: 0.8410 - matthews_correlation: 0.6881\n",
      "Epoch 33/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.3572 - acc: 0.8533 - matthews_correlation: 0.7129\n",
      "Epoch 34/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.4104 - acc: 0.8029 - matthews_correlation: 0.6320\n",
      "Epoch 35/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.3555 - acc: 0.8476 - matthews_correlation: 0.7119\n",
      "Epoch 36/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.3724 - acc: 0.8314 - matthews_correlation: 0.6692\n",
      "Epoch 37/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.3967 - acc: 0.8448 - matthews_correlation: 0.6942\n",
      "Epoch 38/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.3202 - acc: 0.8714 - matthews_correlation: 0.7441\n",
      "Epoch 39/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.3248 - acc: 0.8714 - matthews_correlation: 0.7472\n",
      "Epoch 40/50\n",
      "1050/1050 [==============================] - 13s 13ms/step - loss: 0.3059 - acc: 0.8752 - matthews_correlation: 0.7576\n",
      "Epoch 41/50\n",
      "1050/1050 [==============================] - 13s 12ms/step - loss: 0.4114 - acc: 0.7952 - matthews_correlation: 0.6369\n",
      "Epoch 42/50\n",
      "1050/1050 [==============================] - 13s 13ms/step - loss: 0.3326 - acc: 0.8552 - matthews_correlation: 0.7216\n",
      "Epoch 43/50\n",
      "1050/1050 [==============================] - 12s 12ms/step - loss: 0.3178 - acc: 0.8781 - matthews_correlation: 0.7561\n",
      "Epoch 44/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.3140 - acc: 0.8752 - matthews_correlation: 0.7520\n",
      "Epoch 45/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.2994 - acc: 0.8867 - matthews_correlation: 0.7729\n",
      "Epoch 46/50\n",
      "1050/1050 [==============================] - 13s 13ms/step - loss: 0.3695 - acc: 0.8267 - matthews_correlation: 0.6802\n",
      "Epoch 47/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.3580 - acc: 0.8400 - matthews_correlation: 0.6893\n",
      "Epoch 48/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.3095 - acc: 0.8771 - matthews_correlation: 0.7544\n",
      "Epoch 49/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.3131 - acc: 0.8705 - matthews_correlation: 0.7498\n",
      "Epoch 50/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.2844 - acc: 0.8895 - matthews_correlation: 0.7808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0ac477b278>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    verbose=1,\n",
    "    callbacks=[m_tb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "notify_time": "5",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "982px",
    "right": "20px",
    "top": "111px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
